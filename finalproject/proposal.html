<!DOCTYPE html>
<html>
<head>
<title>proposal.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="centerlightweight-neural-radiance-fields-nerf-viewercenter"><center>Lightweight Neural Radiance Fields (NeRF) Viewer</center></h1>
<p>Link to this page: <a href="https://cal-cs184-student.github.io/hw-webpages-my-team-lol/finalproject/proposal.html">https://cal-cs184-student.github.io/hw-webpages-my-team-lol/finalproject/proposal.html</a></p>
<h2 id="team-members">Team Members</h2>
<ul>
<li>Arhaan Aggarwal-3036541288</li>
<li>Riley Udagawa-3037299846</li>
<li>Mateus Ikezaki-3037194420</li>
<li>Sirawich Smitsomboon-3037647420</li>
</ul>
<h2 id="project-summary">Project Summary</h2>
<p>We want to develop a lightweight NeRF (Neural Radiance Fields) Viewer that reconstructs a photorealistic 3D scene from a sparse set of 2D input images. Our system will take in several images and their corresponding camera poses, train a neural network to learn the volumetric radiance field of the scene, and render novel views using volumetric rendering. Our goal is to create an interactive viewer where users can orbit and inspect the reconstructed 3D scene from arbitrary viewpoints. We plan to implement a basic NeRF in PyTorch and later explore integrating NVIDIA's Instant-NGP for fast training and real-time rendering.</p>
<h2 id="problem-description">Problem Description</h2>
<p>Traditional 3D reconstruction methods rely on mesh-based geometry and texture mapping, which often struggle with view dependent effects and fine details. NeRFs provide a good alternative by learning a continuous volumetric scene representation using deep learning. However, standard NeRF implementations are computationally expensive and not interactive. This project aims to bridge that gap by building a lightweight, interactive NeRF viewer that runs efficiently and produces compelling visual results, making the technology more accessible and usable.</p>
<h2 id="goals-and-deliverables">Goals and Deliverables</h2>
<p><strong>Minimum Viable Deliverables (for base grade):</strong></p>
<ul>
<li>Implement a basic NeRF pipeline in PyTorch.</li>
<li>Support rendering of novel views using volumetric rendering.</li>
<li>Demonstrate scene reconstructions using synthetic datasets (e.g., Blender NeRF scenes or LLFF).</li>
<li>Include a webpage report and flythrough demo video.</li>
</ul>
<p><strong>Target Deliverables (for full grade):</strong></p>
<ul>
<li>Integrate a real-time NeRF renderer using Instant-NGP.</li>
<li>Implement an interactive GUI viewer with camera controls.</li>
<li>Visualize multiple datasets (indoor, outdoor, synthetic).</li>
<li>Add simple styling or relighting effects (optional).</li>
</ul>
<p><strong>Stretch Goals:</strong></p>
<ul>
<li>Build a web-based viewer using Three.js or WebGL.</li>
<li>Support real-time NeRF relighting or stylized NeRFs.</li>
<li>Compare reconstruction quality across datasets or NeRF variants.</li>
</ul>
<h2 id="schedule">Schedule</h2>
<table>
<thead>
<tr>
<th>Week</th>
<th>Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td>04/01-04/06</td>
<td>Finalize team &amp; proposal, choose datasets, set up environment, prepare image and camera pose pipeline using COLMAP or dataset loader.</td>
</tr>
<tr>
<td>04/07-04/13</td>
<td>Implement core NeRF model in PyTorch, render basic novel views, verify training on test datasets.</td>
</tr>
<tr>
<td>04/14-04/20</td>
<td>Integrate Instant-NGP or other acceleration methods, polish rendering pipeline, begin building viewer. Submit milestone report &amp; video.</td>
</tr>
<tr>
<td>04/21-04/28</td>
<td>Midterm preparation Week (less work)</td>
</tr>
<tr>
<td>04/28-05/04</td>
<td>Finalize interactive viewer and GUI, optimize for speed and quality, record final flythrough video, write report and polish website. Prepare for presentation.</td>
</tr>
</tbody>
</table>
<h2 id="resources">Resources</h2>
<p><strong>Code Frameworks:</strong> PyTorch, Tiny-CUDA-NeRF, Instant-NGP (NVIDIA), COLMAP</p>
<p><strong>Hardware:</strong> Personal/local GPUs, Google Colab Pro</p>
<p><strong>Datasets:</strong></p>
<ul>
<li>LLFF (Local Light Field Fusion)</li>
<li>Blender NeRF synthetic dataset</li>
<li>Custom photo dataset (optional)</li>
</ul>
<h2 id="external-resources">External Resources</h2>
<ul>
<li><a href="https://arxiv.org/abs/2003.08934">arxiv.org/abs/2003.08934</a></li>
<li><a href="https://github.com/NVlabs/instant-ngp">github.com/NVlabs/instant-ngp</a></li>
<li><a href="https://github.com/colmap/colmap">github.com/colmap/colmap</a></li>
</ul>

</body>
</html>
